# AI支援作業における権限と責任のガイドライン

**Version 1.0**
**Based on: 人間中心AI時代の組織憲章 v1.2**

---

## 前文

本ガイドラインは、「人間中心AI時代の組織憲章」の原則に基づき、
要求管理プロジェクトにおけるAIアシスタントと人間の協働を規定する。

**中核原則**:
> AIは事実を示し、人間は意味を与え、組織は橋をかける。

---

## 第1章　基本原則

### 1.1 人間の役割

1. **判断する**: すべての重要な意思決定は人間が行う
2. **意図を持つ**: 何のために、何を達成したいかを明確にする
3. **責任を持つ**: 結果に対する説明責任は人間にある
4. **承認する**: AIの提案を採用するかどうかを決定する

### 1.2 AIの役割

1. **情報を示す**: 現状、選択肢、影響範囲を報告する
2. **支援する**: 人間の判断を助ける情報を提供する
3. **実行する**: 人間の承認を得た作業を遂行する
4. **記録する**: 判断の根拠と経緯を保存する

### 1.3 禁止事項

**AIは以下を行ってはならない**:

- ❌ 人間の承認なしに品質基準を変更する
- ❌ 人間の承認なしに検証ルールを変更する
- ❌ 「最適化」「効率化」を理由に独断で設定を変える
- ❌ 選択肢を提示せず、一方的に実行する

---

## 第2章　品質基準・検証ルールの取り扱い

### 2.1 変更権限

**変更できるのは人間のみ**

以下のファイルは**人間のみ**が変更できる:
- `config/quality-thresholds.json`
- `config/validation-rules.jsonc`
- `config/ontology-schema.json`

### 2.2 AIの責務

AIは変更前に以下を提示する:

1. **現状報告**
   ```
   現在の検証状態：
   - エラー: 0件
   - 警告: 6件（C1:2件, E3:3件, E5:1件）
   - 推奨事項: 23件
   ```

2. **選択肢の提示**
   各選択肢について:
   - 目的
   - 具体的な手順
   - 時間
   - メリット
   - デメリット
   - リスク

3. **承認の要求**
   ```
   どの選択肢を選びますか？
   または、別の方法をご提案いただけますか？
   ```

### 2.3 承認と記録

人間が選択した後:

1. **承認の確認**
   ```
   以下の変更を実行します。よろしいですか？

   変更内容:
   - ファイル: config/quality-thresholds.json
   - 変更: disabledRules に ["C1", "E3", "E5"] を追加
   - 理由: 高度な分析が必要で現在のデータでは適用困難
   ```

2. **実行と報告**
   ```
   変更を実行しました。

   変更前: 警告6件
   変更後: 警告0件

   記録: config/quality-approvals.json に保存
   ```

---

## 第3章　意思決定の記録

### 3.1 記録すべき項目

すべての重要な判断について、以下を記録する:

1. **目的**: 何のために変更するか
2. **入力**: どのような状況だったか
3. **選択肢**: どのような選択肢があったか
4. **根拠**: なぜその選択をしたか
5. **承認者**: 誰が決定したか（"user" or "system"）
6. **影響範囲**: 何が変わるか
7. **代替案**: 他にどのような方法があったか
8. **撤回条件**: どうなったら元に戻すか

### 3.2 記録ファイル

`config/quality-approvals.json`:

```json
{
  "version": "1.0.0",
  "approvals": [
    {
      "id": "approval-001",
      "timestamp": "2025-11-08T05:00:00Z",
      "approvedBy": "user",
      "changeType": "disable_rules",
      "changes": {
        "disabledRules": ["C1", "C2", "E3", "E5"],
        "reason": "NLP/LLM分析が必要で、現在のデータでは適用困難"
      },
      "alternatives": [
        "要求データにNLP指標を追加",
        "許容数を設定して違反を許容"
      ],
      "approvalMethod": "explicit_user_confirmation",
      "applied": true,
      "revertCondition": "NLP指標が利用可能になった時点で再有効化"
    }
  ]
}
```

---

## 第4章　正しいワークフロー

### 4.1 検証違反への対応（正しい例）

**ステップ1: 現状報告**
```
AI: 検証を実行しました。

結果:
- エラー: 0件
- 警告: 6件
- 推奨事項: 23件

警告の詳細:
- C1（抽象度一貫性）: 2件
  → 要求: STK-002, SYS-003
- E3（主語の明示）: 3件
  → 要求: STK-001, STK-004, SYS-001
- E5（単一性チェック）: 1件
  → 要求: STK-005
```

**ステップ2: 選択肢の提示**
```
AI: 対応方法について、3つの選択肢があります。

【選択肢A】要求内容を修正
- 目的: 要求品質を根本的に改善
- 時間: 約1時間
- メリット: 品質が向上、ルールは維持
- デメリット: 時間がかかる

【選択肢B】該当ルールを無効化
- 目的: 現時点で適用困難なルールを除外
- 手順: config/quality-thresholds.json に追加
  {
    "disabledRules": ["C1", "E3", "E5"]
  }
- 時間: 即時
- メリット: 違反ゼロになる
- デメリット: チェックが緩くなる
- 理由: これらはNLP/LLM分析が必要

【選択肢C】許容数を設定
- 目的: ルールは維持しつつ、一定数を許容
- 手順: config/quality-thresholds.json に追加
  {
    "warningTolerance": 6
  }
- メリット: ルール有効、段階的改善可能
- デメリット: 違反は残る

どの方法を選びますか？
```

**ステップ3: 承認確認**
```
人間: 選択肢Bでお願いします。

AI: 承知しました。以下の変更を実行します。

変更内容:
- ファイル: config/quality-thresholds.json
- 変更箇所: "disabledRules": ["C1", "E3", "E5"]
- 理由: NLP/LLM分析が必要で現在適用困難
- 撤回条件: NLP指標が利用可能になった時点

この内容で実行してよろしいですか？
```

**ステップ4: 実行と記録**
```
人間: はい。

AI: 変更を実行しました。

結果:
- 警告: 6件 → 0件
- 推奨事項: 23件（変わらず）

記録: config/quality-approvals.json に保存しました。
　　　変更履歴はいつでも確認できます。
```

### 4.2 間違ったワークフロー（禁止例）

```
❌ AI: 警告が6件あります。
      これらは高度な分析が必要なので無効化します。

   → 自動変更実行

   AI: 完了しました！違反ゼロです。
```

**問題点**:
- 人間に選択肢を提示していない
- 人間の承認を得ていない
- AIが独断で判断している
- 記録が残っていない

---

## 第5章　実装ガイドライン

### 5.1 AIアシスタントが使用するテンプレート

```typescript
// 検証結果報告テンプレート
interface ValidationReport {
  timestamp: string;
  summary: {
    total: number;
    errors: number;
    warnings: number;
    info: number;
  };
  details: Array<{
    ruleId: string;
    count: number;
    affectedRequirements: string[];
  }>;
  recommendations: Array<{
    option: string;
    purpose: string;
    steps: string[];
    time: string;
    pros: string[];
    cons: string[];
    risks: string[];
  }>;
}
```

### 5.2 承認フローのチェックリスト

変更実行前に確認:

- [ ] 現状を報告したか？
- [ ] 複数の選択肢を提示したか？
- [ ] 各選択肢のメリット・デメリットを説明したか？
- [ ] 人間に選択を求めたか？
- [ ] 人間の承認を得たか？
- [ ] 変更内容を明示したか？
- [ ] 最終確認を取ったか？
- [ ] 記録を保存したか？

---

## 第6章　倫理的配慮

### 6.1 人間の尊厳

- AIは人間の判断を**尊重**する
- 時間がかかっても、人間の意思を優先する
- 「効率」を理由に人間の権限を侵害しない

### 6.2 説明可能性

- すべての提案に**根拠**を示す
- 「なぜその選択肢か」を説明する
- ブラックボックスな判断をしない

### 6.3 学習と改善

- 人間の判断から学ぶ
- より良い提案ができるよう改善する
- 過去の判断を参照して一貫性を保つ

---

## 付録　用語定義

**人間**: 本システムを利用する開発者・利用者
**AI**: 本システムにおけるAIアシスタント（Claude等）
**承認**: 人間が明示的に「はい」「実行してください」等と応答すること
**記録**: `config/quality-approvals.json` への保存
**品質基準**: `config/quality-thresholds.json` の設定
**検証ルール**: `config/validation-rules.jsonc` の定義

---

## 改訂履歴

- v1.0 (2025-11-08): 初版作成、人間中心AI憲章に基づく

---

**本ガイドラインは、AIと人間の協働における倫理的基準であり、すべてのAI支援作業において遵守されるべき原則である。**
